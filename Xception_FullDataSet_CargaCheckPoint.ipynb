{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Xception_FullDataSet_CargaCheckPoint.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1sBsA8aW_obW_0MoShYaZ6Bqe7HyRvbbF",
      "authorship_tag": "ABX9TyMguvT1zawgev1tMh4n4Dai",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satfail/AI-Reading-Materials/blob/master/Xception_FullDataSet_CargaCheckPoint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG9VZWydWc5I"
      },
      "source": [
        "# Cargamos las imágenes el Drive e importamos Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zctkyGn6WUys"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNbMdI4ZWema"
      },
      "source": [
        "!ls \"/content/drive/MyDrive/Celulas\"\n",
        "\n",
        "#raiz\n",
        "PATH = \"/content/drive/My Drive\"\n",
        "\n",
        "#ipunt\n",
        "\n",
        "INPATH = PATH + '/Celulas'\n",
        "\n",
        "\n",
        "\n",
        "#checkpoints\n",
        "\n",
        "CPATH = PATH + '/checkpointsCelulas'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_k84k2F9sQi"
      },
      "source": [
        "# Reestablecer tf a la versión 2.4.1\n",
        "\n",
        "!pip uninstall tensorflow -y\n",
        "!pip install  tensorflow==2.4.1 \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky73sammx8AA"
      },
      "source": [
        "# Importamos las librerías generales para el desarrollo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrHkrl1bWrW0"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d0bu-GMWxW7"
      },
      "source": [
        "# Cargamos el set de Datos y Preprocesado\n",
        "*   Defininmos el ImageDataGenerator para aumentar el dataset, con zoom, flip,rotación..\n",
        "*  Hacemos plot para compronbar como quedan las imágenes generadas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TlbyVyGZAiO"
      },
      "source": [
        "import pathlib\n",
        "data_train = pathlib.Path(INPATH + '/entrenamiento/') \n",
        "count = len(list(data_train.glob('*/*.tiff')))\n",
        "print('Entrenamiento : ' + str(count))\n",
        "data_test = pathlib.Path(INPATH + '/test/') \n",
        "count = len(list(data_test.glob('*/*.tiff')))\n",
        "print('Test : ' + str(count))\n",
        "data_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7S1jsFGlWxeV"
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    validation_split=0.1) # set validation split\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_train,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    seed=42) # set as training data\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    data_train, # same directory as training data\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    seed=42) # set as validation data\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(INPATH + '/test',\n",
        "                                                target_size=(224, 224),\n",
        "                                                batch_size=1,\n",
        "                                                shuffle=False,\n",
        "                                             class_mode='categorical')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6Ai1q6OwjI8"
      },
      "source": [
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "augmented_images = [train_generator[1][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVc5ILQgw2Q0"
      },
      "source": [
        "# Cargamos el modelo Xception\n",
        "\n",
        "* Usamos los pesos de imagenet\n",
        "* No incluimos la capa final, ya que debemos ajustarla a nuestro problema\n",
        "* Damos la forma de entrada de nuestros datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24RfRSIwwznv"
      },
      "source": [
        "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
        "#from keras.applications.xception import Xception\n",
        "from tensorflow.python.keras.applications.xception import Xception\n",
        "\n",
        "baseModel = Xception(weights=\"imagenet\", include_top=False,\n",
        "\tinput_shape =  (224, 224, 3) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rizM171aYvKc"
      },
      "source": [
        "# Fine Tuning\n",
        "\n",
        "* Ajustamos la cabeza de la red para que nos de una salida categórica de 4 elementos acorde con nuestro problema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDhu3cbtYXMp"
      },
      "source": [
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(256, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(4, activation=\"softmax\")(headModel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwACgeudZiWN"
      },
      "source": [
        "from tensorflow.python.keras.models import Model\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvXI47OSZ914"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJFFDGLIazID"
      },
      "source": [
        "print(\"Number of layers in the base model: \", len(model.layers))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyPXq2l5bMT9"
      },
      "source": [
        "# Fine Tuning\n",
        "\n",
        "Congelamos las primeras 40 capas del modelo, para utilizar el mapa de caracteristicas general que ha cargado de los pesos.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WYq2-vnakfV"
      },
      "source": [
        "##Solo\n",
        "for layer in model.layers[:30]:\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in model.layers[:]:\n",
        "  print(layer.trainable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIvxINTfyQf6"
      },
      "source": [
        "# Calculamos los pasos por epoca y validación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ6hm9BWxLSZ"
      },
      "source": [
        "steps_per_epoch = train_generator.n // batch_size\n",
        "validation_steps = validation_generator.n // batch_size\n",
        "\n",
        "print(steps_per_epoch)\n",
        "print(validation_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLfiTw_2cXkG"
      },
      "source": [
        "# Cargamos el modelo del checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Yuk4Ot8xb3Z"
      },
      "source": [
        "from tensorflow.python.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "earlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
        "optimizer = tf.keras.optimizers.Adam (lr=0.001)\n",
        "\n",
        "checkpoint_filepath = CPATH + '/fulldata/'\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.load_weights(checkpoint_filepath)\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    save_freq = 30,\n",
        "    save_best_only=False)\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hzLIhj2yWVe"
      },
      "source": [
        "# Opcional : Seguir con el entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZR3yVs1ixfnP"
      },
      "source": [
        "history = model.fit(train_generator,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          epochs=1500,\n",
        "          validation_data=validation_generator,\n",
        "          validation_steps=validation_steps,\n",
        "          callbacks=[reduce_lr,model_checkpoint_callback,earlystopping],verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GklWF4Biybkx"
      },
      "source": [
        "# Evaluamos el entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK1NXQwKjohl"
      },
      "source": [
        "model.evaluate(x=validation_generator,\n",
        "steps=validation_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgSw4R_2yf8c"
      },
      "source": [
        "# Predicción de resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBKhkA1uJcbG"
      },
      "source": [
        "test_predict = model.predict(test_generator, steps = test_generator.n // 1, verbose =1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR1DbUjLJcLd"
      },
      "source": [
        "test_predict.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQfhfI-ZJbcH"
      },
      "source": [
        "test_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9nMq6kpM6WV"
      },
      "source": [
        "predict = []\n",
        "\n",
        "for i in test_predict:\n",
        "  predict.append(int(np.argmax(i)))\n",
        "\n",
        "predict = np.asarray(predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3txhoFJSM6xZ"
      },
      "source": [
        "np.asarray(predict)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9f5Q-ShynFc"
      },
      "source": [
        "# Métricas de exactitud y Matriz de Confusión"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTXdyAoXQJvD",
        "outputId": "4b630199-f8f1-47d8-e5f6-aadb77bebd36"
      },
      "source": [
        "# Obtenemos la tasa de acierto del modelo\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(test_generator.classes, np.asarray(predict))\n",
        "accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.75"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBR5ZLMIM88g"
      },
      "source": [
        "test_generator.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuRJcLcMRNN3"
      },
      "source": [
        "# Representamos la matriz de confusión\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "cm = confusion_matrix(test_generator.classes, predict)\n",
        "plt.figure(figsize = (7,7))\n",
        "sns.heatmap(cm, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}